<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="generator" content="Hugo 0.24.1" />

  <title>Hov&#39;s Blog</title>

  <script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "https://hm.baidu.com/hm.js?dd096f3aba9332e2640cda59d3786695";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>	
  
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.2/pure-min.css">

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.2/grids-responsive-old-ie-min.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.2/grids-responsive-min.css">
  <!--<![endif]-->

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://HauyuChen.github.io/css/side-menu-old-ie.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://HauyuChen.github.io/css/side-menu.css">
  <!--<![endif]-->

  <link rel="stylesheet" href="https://HauyuChen.github.io/css/blackburn.css">

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

  
  <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">

  
  
  <link rel="alternate" type="application/rss+xml" title="Hov&#39;s Blog" href="https://HauyuChen.github.io/index.xml" />
  

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/styles/androidstudio.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  

  <link rel="shortcut icon" href="https://HauyuChen.github.io/img/favicon.ico" type="image/x-icon" />

  
  


</head>


<body>

<div id="layout">

  
<a href="#menu" id="menuLink" class="menu-link">
  
  <span></span>
</a>
<div id="menu">

  <a class="pure-menu-heading brand" href="https://HauyuChen.github.io/">
  <img src="https://HauyuChen.github.io/img/Hov.jpg" width="125px">
</a>

  <div class="pure-menu">
    <ul class="pure-menu-list">
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://HauyuChen.github.io/"><i class='fa fa-home fa-fw'></i>主页</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://HauyuChen.github.io/post/"><i class='fa fa-list fa-fw'></i>所有文章</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://HauyuChen.github.io/tags/"><i class='fa fa-tags fa-fw'></i>文章分类</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://HauyuChen.github.io/topics/"><i class='fa fa-folder fa-fw'></i>关键词</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://HauyuChen.github.io/about/"><i class='fa fa-user fa-fw'></i>关于我</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://HauyuChen.github.io/contact/"><i class='fa fa-home fa-fw'></i>关于本站</a>
      
        </li>
      
    </ul>
  </div>

  <div class="pure-menu social">

  <ul class="pure-menu-list">
	
    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://HauyuChen.github.io/index.xml"><i class="fa fa-rss fa-fw"></i>RSS</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://github.com/HauyuChen" target="_blank"><i class="fa fa-github-square fa-fw"></i>GitHub</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

  </ul>
  
</div>


  <div>


</div>

</div>


  <div id="main">


<div class="header">
  <h1>Hov&#39;s Blog</h1>
  <h2>To code,  To record,  To recall.</h2>
  
</div>

<div class="content">
  
    <article>
  <header>
    <h2><a href="https://HauyuChen.github.io/post/ml-4-logisticregression/">【机器学习笔记】4. 逻辑回归</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2017-08-03</time>
  </div>

  

  
  
  
  <div>
    <i class="fa fa-folder fa-fw"></i>
    
      <a class="post-taxonomy-topic" href="https://HauyuChen.github.io/topics/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>&nbsp;&#47;
    
      <a class="post-taxonomy-topic" href="https://HauyuChen.github.io/topics/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92">逻辑回归</a>&nbsp;&#47;
    
      <a class="post-taxonomy-topic" href="https://HauyuChen.github.io/topics/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">监督学习</a>
    
  </div>
  
  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="https://HauyuChen.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>
    
  </div>
  
  

</div>

  </header>

  <p>
  作者注：机器学习系列是本人在学习机器学习相关内容时产生的笔记，希望也能对您有所帮助。值得注意的是，作者作为初学者，表述难免有误或不全面，望多批评指正。 如有任何问题，欢迎您随时与我联系：Hauyu.Chen@Gmail.com
版权声明：本文由 Hov 所有，发布于 http://chenhy.com ，转载请注明出处。

0 前言 本文要讲的逻辑回归属于分类算法，它是对线性回归的改进。
在处理二分类问题的时候，我们可将所有预测 y 映射成某个值。假设，若该值大于等于0.5，则结果为1；若该值小于0.5，则结果为0。这样，我们就将所有样本分为两类了。
若用线性回归去处理分类问题， y 的值可能远大于1或小于0，这样会造成较大的误差，所以能否让 y 的值处于0到1之间呢？
逻辑回归实现的就是这样的功能，将预测值映射到某个固定的区间，通过决策边界，实现二分类问题。

1 要点 1.1 逻辑函数（Sigmoid函数） 逻辑回归中的逻辑函数其实就是线性回归中的假设函数，只不过在假设函数的基础上进行一个函数映射。
（1）线性回归中的假设函数
（2）逻辑回归中的逻辑函数
逻辑函数对应的图像如下：
可见，逻辑函数将所有预测映射到（0，1）区间。
1.2 Decision Boundary（决策边界） 为了对输出结果进行0和1的分类，我们假设认为 hθ(x) 大于等于0.5，则结果 y=1 ；若 hθ(x) 小于0.5，则结果 y=0 ，即：
根据逻辑函数的图像，有：
即：
所以，决策边界就是将结果分为 y=0 和 y=1 的分界，不同的参数向量 θ ，可对应不同的决策边界。
举个栗子：
这个栗子中，决策边界为 x=5 ，因为在其左边，y=1；在其右边，y=0。
当然，决策边界并非只能是直线，也可能是复杂的曲线。
1.3 Cost Function（代价函数） 上述公式可简化如下：
向量化如下：
1.4 Gradient Descent（梯度下降） 
2 思路 假设，我们要实现邮件的分类（垃圾邮件、非垃圾邮件）
 借助线性回归的思路，我们可以设定假设函数 hθ(x)=θ0*x0+θ1*x1+⋯+θn*xn ，但 hθ(x) 的结果可能在 (−∞,+∞) 之间。 所以，我们通过构造逻辑回归将预测值映射到（0，1）区间，预测值表示该邮件是垃圾邮件的概率。 构造代价函数。 通过梯度下降来最优化特征向量 θ ，求得决策边界。
  </p>

  
  <footer>
    <a href="https://HauyuChen.github.io/post/ml-4-logisticregression/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="https://HauyuChen.github.io/post/java-json/">JSON相关操作（Java）</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2017-08-01</time>
  </div>

  

  
  
  
  <div>
    <i class="fa fa-folder fa-fw"></i>
    
      <a class="post-taxonomy-topic" href="https://HauyuChen.github.io/topics/json">JSON</a>&nbsp;&#47;
    
      <a class="post-taxonomy-topic" href="https://HauyuChen.github.io/topics/java">Java</a>
    
  </div>
  
  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="https://HauyuChen.github.io/tags/java">Java</a>
    
  </div>
  
  

</div>

  </header>

  <p>
  1 Java中创建JSON import com.google.gson.JsonArray; import com.google.gson.JsonObject; public class CreateJSON { public static void main(String[] args) { JsonObject object = new JsonObject(); object.addProperty(&quot;cat&quot;, &quot;it&quot;); JsonArray array = new JsonArray(); JsonObject lan1 = new JsonObject(); lan1.addProperty(&quot;id&quot;, 1); lan1.addProperty(&quot;name&quot;, &quot;Java&quot;); lan1.addProperty(&quot;ide&quot;, &quot;Eclipse&quot;); array.add(lan1); JsonObject lan2 = new JsonObject(); lan2.addProperty(&quot;id&quot;, 2); lan2.addProperty(&quot;name&quot;, &quot;Swift&quot;); lan2.addProperty(&quot;ide&quot;, &quot;XCode&quot;); array.add(lan2); JsonObject lan3 = new JsonObject(); lan3.addProperty(&quot;id&quot;, 3); lan3.addProperty(&quot;name&quot;, &quot;C#&quot;); lan3.addProperty(&quot;ide&quot;, &quot;Visual Studio&quot;); array.add(lan3); object.add(&quot;languages&quot;, array); object.addProperty(&quot;pop&quot;, true); System.
  </p>

  
  <footer>
    <a href="https://HauyuChen.github.io/post/java-json/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="https://HauyuChen.github.io/post/java-xml/">XML相关操作（Java）</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2017-08-01</time>
  </div>

  

  
  
  
  <div>
    <i class="fa fa-folder fa-fw"></i>
    
      <a class="post-taxonomy-topic" href="https://HauyuChen.github.io/topics/xml">XML</a>&nbsp;&#47;
    
      <a class="post-taxonomy-topic" href="https://HauyuChen.github.io/topics/java">Java</a>
    
  </div>
  
  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="https://HauyuChen.github.io/tags/java">Java</a>
    
  </div>
  
  

</div>

  </header>

  <p>
  1 XML文件创建示例 import java.io.File; import java.io.StringWriter; import javax.xml.parsers.DocumentBuilder; import javax.xml.parsers.DocumentBuilderFactory; import javax.xml.parsers.ParserConfigurationException; import javax.xml.transform.Transformer; import javax.xml.transform.TransformerConfigurationException; import javax.xml.transform.TransformerException; import javax.xml.transform.TransformerFactory; import javax.xml.transform.dom.DOMSource; import javax.xml.transform.stream.StreamResult; import org.w3c.dom.Document; import org.w3c.dom.Element; public class CreateXML { public static void main(String[] args) { try { //DOM DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); DocumentBuilder builder = factory.newDocumentBuilder(); Document document = builder.newDocument(); //创建Languages标签 Element root = document.createElement(&quot;Languages&quot;); root.setAttribute(&quot;cat&quot;, &quot;it&quot;); //设置Languages标签的属性 //-----接下来创建Languages标签下的三个子标签lan1、lan2、lan3 //lan1 Element lan1 = document.createElement(&quot;lan&quot;); //lan标签 lan1.setAttribute(&quot;id&quot;, &quot;1&quot;); Element name1 = document.
  </p>

  
  <footer>
    <a href="https://HauyuChen.github.io/post/java-xml/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="https://HauyuChen.github.io/post/ml-3-linearregression-multiplevariables/">【机器学习笔记】3. 线性回归（多变量）</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2017-07-31</time>
  </div>

  

  
  
  
  <div>
    <i class="fa fa-folder fa-fw"></i>
    
      <a class="post-taxonomy-topic" href="https://HauyuChen.github.io/topics/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>&nbsp;&#47;
    
      <a class="post-taxonomy-topic" href="https://HauyuChen.github.io/topics/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92">线性回归</a>&nbsp;&#47;
    
      <a class="post-taxonomy-topic" href="https://HauyuChen.github.io/topics/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">监督学习</a>
    
  </div>
  
  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="https://HauyuChen.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>
    
  </div>
  
  

</div>

  </header>

  <p>
  作者注：机器学习系列是本人在学习机器学习相关内容时产生的笔记，希望也能对您有所帮助。值得注意的是，作者作为初学者，表述难免有误或不全面，望多批评指正。 如有任何问题，欢迎您随时与我联系：Hauyu.Chen@Gmail.com
版权声明：本文由 Hov 所有，发布于 http://chenhy.com ，转载请注明出处。

0 前言 前面我们已经提到了单变量线性回归，现在讲讲多元线性回归（多变量线性回归）。
在讲解单变量线性回归时，我们引入了房价预测这个栗子，仅通过房屋面积来预测房价。事实上，影响房价的因素有很多，如面积、房间数量、楼层、房龄等等。
现在，我们想在进行房价预测时考虑面积、房间数量、楼层、房龄这几个因素，而不是单单只考虑面积。
显然，单变量线性回归已不再适用，我们可以通过多元线性回归来解决。

1 要点 1.1 多元线性回归模型 这条公式是否很熟悉呢？其实就是在单变量线性回归模型的基础上增加了其它的特征 x2、x3、x4 ··· xn。
为方便计算，我们可以定义 x0=1 ，现在可以将公式转化成如下形式：
令： 特征向量X = [x0,x1,x2, &hellip; ,xn] 参数向量θ = [θ0,θ1,θ2, &hellip; ,θn] X 和 θ 均为 n+1 维向量，有：
最后，假设函数h可简化成以下形式：
1.2 Cost Function（代价函数） 注：多元线性回归的代价函数和单变量线性回归的一致，不过增加了一些新的参数θ3、θ4、θ5···θn。
1.3 Batch Gradient Descent（批量梯度下降） 
2 思路 多元线性回归的思路和单变量线性回归大体一致，只不过我们需要对计算公式做一些微小改变。
同样，还是通过房价预测的栗子来讲解：
 房价取决于多方面的因素，在这里我们考虑面积、房间数量、楼层、房龄这四个因素。所以，我们要搞清楚的就是面积 x1 、房间数量 x2 、楼层 x3 、房龄 x4 对房价 y 的影响。 所以，假设函数为 hθ(x) = θ0 + θ1*x1+ θ2*x2 + θ3*x3+ θ4*x4 。 令 x0=1 ，将假设函数转换成 hθ(x) = θ0*x0 + θ1*x1+ θ2*x2 + θ3*x3+ θ4*x4 。 令特征向量 X=[x0,x1,x2,x3,x4] ,参数向量 θ=[θ0,θ1,θ2,θ3,θ4] ,最终我们的假设函数为 hθ(x)=(θ^T)X 。 问题的核心还是找出合适的参数向量θ，使得我们的预测 hθ(x) 是合理的。 衡量参数向量 θ 是否合适的标准就是代价函数 J(0) ，θ 应使得 J(θ) 尽可能小。
  </p>

  
  <footer>
    <a href="https://HauyuChen.github.io/post/ml-3-linearregression-multiplevariables/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="https://HauyuChen.github.io/post/ml-2-gradientdescent/">【机器学习笔记】2. 梯度下降法</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2017-07-26</time>
  </div>

  

  
  
  
  <div>
    <i class="fa fa-folder fa-fw"></i>
    
      <a class="post-taxonomy-topic" href="https://HauyuChen.github.io/topics/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>&nbsp;&#47;
    
      <a class="post-taxonomy-topic" href="https://HauyuChen.github.io/topics/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">监督学习</a>&nbsp;&#47;
    
      <a class="post-taxonomy-topic" href="https://HauyuChen.github.io/topics/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D">梯度下降</a>
    
  </div>
  
  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="https://HauyuChen.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>
    
  </div>
  
  

</div>

  </header>

  <p>
  作者注：机器学习系列是本人在学习机器学习相关内容时产生的笔记，希望也能对您有所帮助。值得注意的是，作者作为初学者，表述难免有误或不全面，望多批评指正。 如有任何问题，欢迎您随时与我联系：Hauyu.Chen@Gmail.com
版权声明：本文由 Hov 所有，发布于 http://chenhy.com ，转载请注明出处。

0 前言 上一篇讲到了线性回归，提到了代价函数（Cost Function）的概念，我们知道我们的目标是找到合适的 θ0、θ1 使得代价函数 J(θ0,θ1) 最小。 但是，若漫无目的地设定 θ0、θ1 的值， J(θ0,θ1) 可能会有无数的结果。 那我们要怎么更快地找到 J(θ0,θ1) 的最小值呢？ 本文将介绍一种重要的优化算法，Gradient Descent（梯度下降法）。

1 什么是梯度？ 在讲解梯度下降法之前，我们必须先了解梯度的概念。 梯度是高等数学中的概念，梯度的指向即为函数增长最快的方向。同理，梯度的反方向即为函数下降最快的方向。 现在你知道为什么梯度下降法是优化算法了吧？它能使我们的代价函数下降的最快！

2 原理 下图为代价函数的三维图形，分别以 θ0、θ1 为 X、Y 轴，以 J(θ0,θ1) 为 Z 轴。求解代价函数最小值的过程可看作是寻找“一座座山坡”中的最低点，因为在“山底”时 J(θ0,θ1)最小。
假定我们随机站在某个山坡上，每次往某个方向向下走一步，怎么走才能最快到山底？这也就是梯度下降法所要解决的，沿着梯度方向最小化 J(θ0,θ1) 。
 确定向下一步的步伐大小，称之为 Learning Rate ； 任取 θ0,θ1 （随机站在某个山坡）； 沿着梯度的反方向，走一个步伐大小，更新 θ0、θ1 ，此时 J(θ0,θ1) 变小； 重复步骤3，当下降的高度小于某个定义的值（已经到山底），则停止下降。  
3 算法  优化目标：J(θ0,θ1)
 优化参数：θ0、θ1
  </p>

  
  <footer>
    <a href="https://HauyuChen.github.io/post/ml-2-gradientdescent/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  

  


<nav class="pagination" role="pagination">
  
  <a href="https://HauyuChen.github.io/page/2/"><i class="fa fa-chevron-left"></i></a>
  
  <span>&nbsp;3 / 16&nbsp;</span>
  
  <a href="https://HauyuChen.github.io/page/4/"><i class="fa fa-chevron-right"></i></a>
  
</nav>



</div>

</div>
</div>
<script src="https://HauyuChen.github.io/js/ui.js"></script>






</body>
</html>

