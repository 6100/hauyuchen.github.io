<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="机器学习系列-第 2 篇">
  <meta name="generator" content="Hugo 0.24.1" />

  <title>【机器学习笔记】2. 梯度下降法 &middot; Hov&#39;s Blog</title>

  <script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "https://hm.baidu.com/hm.js?dd096f3aba9332e2640cda59d3786695";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>	
  
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.2/pure-min.css">

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.2/grids-responsive-old-ie-min.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.2/grids-responsive-min.css">
  <!--<![endif]-->

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://HauyuChen.github.io/css/side-menu-old-ie.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://HauyuChen.github.io/css/side-menu.css">
  <!--<![endif]-->

  <link rel="stylesheet" href="https://HauyuChen.github.io/css/blackburn.css">

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

  
  <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">

  
  

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/styles/androidstudio.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  

  <link rel="shortcut icon" href="https://HauyuChen.github.io/img/favicon.ico" type="image/x-icon" />

  
  


</head>


<body>

<div id="layout">

  
<a href="#menu" id="menuLink" class="menu-link">
  
  <span></span>
</a>
<div id="menu">

  <a class="pure-menu-heading brand" href="https://HauyuChen.github.io/">
  <img src="https://HauyuChen.github.io/img/Hov.jpg" width="125px">
</a>

  <div class="pure-menu">
    <ul class="pure-menu-list">
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://HauyuChen.github.io/"><i class='fa fa-home fa-fw'></i>主页</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://HauyuChen.github.io/post/"><i class='fa fa-list fa-fw'></i>所有文章</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://HauyuChen.github.io/tags/"><i class='fa fa-tags fa-fw'></i>文章分类</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://HauyuChen.github.io/topics/"><i class='fa fa-folder fa-fw'></i>关键词</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://HauyuChen.github.io/about/"><i class='fa fa-user fa-fw'></i>关于我</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://HauyuChen.github.io/contact/"><i class='fa fa-home fa-fw'></i>关于本站</a>
      
        </li>
      
    </ul>
  </div>

  <div class="pure-menu social">

  <ul class="pure-menu-list">
	
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://github.com/HauyuChen" target="_blank"><i class="fa fa-github-square fa-fw"></i>GitHub</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

  </ul>
  
</div>


  <div>


</div>

</div>


  <div id="main">


<div class="header">
  <h1>【机器学习笔记】2. 梯度下降法</h1>
  <h2>机器学习系列-第 2 篇</h2>
</div>
<div class="content">

  <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2017-07-26</time>
  </div>

  

  
  
  
  <div>
    <i class="fa fa-folder fa-fw"></i>
    
      <a class="post-taxonomy-topic" href="https://HauyuChen.github.io/topics/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>&nbsp;&#47;
    
      <a class="post-taxonomy-topic" href="https://HauyuChen.github.io/topics/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">监督学习</a>&nbsp;&#47;
    
      <a class="post-taxonomy-topic" href="https://HauyuChen.github.io/topics/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D">梯度下降</a>
    
  </div>
  
  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="https://HauyuChen.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>
    
  </div>
  
  

</div>

  

<hr />

<p><em>作者注：机器学习系列是本人在学习机器学习相关内容时产生的笔记，希望也能对您有所帮助。值得注意的是，作者作为初学者，表述难免有误或不全面，望多批评指正。<br/>
如有任何问题，欢迎您随时与我联系：Hauyu.Chen@Gmail.com</em></p>

<p><em>版权声明：本文由 Hov 所有，发布于 <a href="http://chenhy.com">http://chenhy.com</a> ，转载请注明出处。<br/></em></p>

<hr />

<p><br/></p>

<h1 id="0-前言">0 前言</h1>

<p>上一篇讲到了线性回归，提到了代价函数（Cost Function）的概念，我们知道我们的目标是找到合适的 θ0、θ1 使得代价函数 J(θ0,θ1) 最小。<br/>
但是，若漫无目的地设定 θ0、θ1 的值， J(θ0,θ1) 可能会有无数的结果。<br/>
那我们要怎么更快地找到 J(θ0,θ1) 的最小值呢？<br/>
本文将介绍一种重要的优化算法，Gradient Descent（梯度下降法）。</p>

<p><br/></p>

<h1 id="1-什么是梯度">1 什么是梯度？</h1>

<p>在讲解梯度下降法之前，我们必须先了解梯度的概念。<br/>
梯度是高等数学中的概念，梯度的指向即为函数增长最快的方向。同理，梯度的反方向即为函数下降最快的方向。<br/>
现在你知道为什么梯度下降法是优化算法了吧？它能使我们的代价函数下降的最快！</p>

<p><br/></p>

<h1 id="2-原理">2 原理</h1>

<p>下图为代价函数的三维图形，分别以 θ0、θ1 为 X、Y 轴，以 J(θ0,θ1) 为 Z 轴。求解代价函数最小值的过程可看作是寻找“一座座山坡”中的最低点，因为在“山底”时 J(θ0,θ1)最小。</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/GD01.PNG" alt="" /></p>

<p>假定我们随机站在某个山坡上，每次往某个方向向下走一步，怎么走才能最快到山底？这也就是梯度下降法所要解决的，沿着梯度方向最小化 J(θ0,θ1) 。</p>

<ol>
<li>确定向下一步的步伐大小，称之为 Learning Rate ；</li>
<li>任取 θ0,θ1 （随机站在某个山坡）；</li>
<li>沿着梯度的反方向，走一个步伐大小，更新 θ0、θ1 ，此时 J(θ0,θ1) 变小；</li>
<li>重复步骤3，当下降的高度小于某个定义的值（已经到山底），则停止下降。</li>
</ol>

<p><br/></p>

<h1 id="3-算法">3 算法</h1>

<ul>
<li><p>优化目标：J(θ0,θ1)</p></li>

<li><p>优化参数：θ0、θ1</p></li>
</ul>

<p>根据梯度下降法原理，可设计算法如下：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/GD02.PNG" alt="" /></p>

<p>图注：</p>

<ol>
<li>蓝色方框： J(θ0,θ1) 的梯度（下降的方向），注意前面的负号，即梯度的反方向</li>
<li>红色方框：下降步伐的大小（Learning Rate）</li>
<li>j=0和1，即同步更新 θ0、θ1</li>
<li>convergence 为终止条件</li>
</ol>

<p><br/></p>

<h1 id="4-feature-scaling-特征缩减">4 Feature Scaling（特征缩减）</h1>

<p>Feature Scaling可应用于梯度下降法中，用于加快梯度下降的执行速度。</p>

<p>常用的方法是 Mean Normalization ，通过将各Feature的值标准化，使得其取值范围在（-1，1），特征缩减公式如下：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/GD04.PNG" alt="" /></p>

<p>注：μi 表示所有特征的平均值，Si 是特征中最大值与最小值的差（max-min）<br/></p>

<p>举个栗子：<br/>
x(i) 表示 price（房价）这个特征，训练集中所有 price 的范围是100到2000，平均值为1000，则 price 特征缩减如下：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/GD05.PNG" alt="" /></p>

<p><br/></p>

<h1 id="5-特性">5 特性</h1>

<ol>
<li>因为初始点 (θ0,θ1) 的选择是随机的，所以不同的初始点 (θ0,θ1) 会得到不同的最小值，因此梯度下降法求得的是局部最小值；</li>
<li>下降的过程中，越接近最小值，下降的速度越慢（因为坡度越来越小了）；</li>
<li>下降步伐 <img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/GDafa.PNG" alt="" />的选择尤为重要，正确的下降步伐应该使代价函数 J(θ0,θ1) 变小。注意：<img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/GDafa.PNG" alt="" />太小的话，则下降的速度会很慢；<img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/GDafa.PNG" alt="" />太大的话，有可能会出现 J(θ0,θ1) 反而变大的情况（overshoot minimum），出现“之字型”（如下图）。<br/>
所以<img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/GDafa.PNG" alt="" />不能太大也不能太小。</li>
</ol>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/GD03.PNG" alt="" /></p>

<p><br/></p>

<h1 id="6-结语">6 结语</h1>

<p>至此，我们已经知道我们的第一个优化算法梯度下降法。通过上一篇提到的线性回归结合本篇的梯度下降法，我们已经可以实现一个简单的机器学习程序。</p>

<p>下篇将讲解多元线性回归。</p>

<p><br/></p>


  
<div class="prev-next-post pure-g">
  <div class="pure-u-1-24" style="text-align: left;">
    
    <a href="https://HauyuChen.github.io/post/ml-1-linearregression-onevariables/"><i class="fa fa-chevron-left"></i></a>
    
  </div>
  <div class="pure-u-10-24">
    
    <nav class="prev">
      <a href="https://HauyuChen.github.io/post/ml-1-linearregression-onevariables/">【机器学习笔记】1. 线性回归（单变量）</a>
    </nav>
    
  </div>
  <div class="pure-u-2-24">
    &nbsp;
  </div>
  <div class="pure-u-10-24">
    
    <nav class="next">
      <a href="https://HauyuChen.github.io/post/ml-3-linearregression-multiplevariables/">【机器学习笔记】3. 线性回归（多变量）</a>
    </nav>
    
  </div>
  <div class="pure-u-1-24" style="text-align: right;">
    
    <a href="https://HauyuChen.github.io/post/ml-3-linearregression-multiplevariables/"><i class="fa fa-chevron-right"></i></a>
    
  </div>
</div>



  
<div id="disqus_thread"></div>
<script type="text/javascript">

(function() {
    
    
    if (window.location.hostname == "localhost")
        return;

    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    var disqus_shortname = "http-hov-space";
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


</div>

</div>
</div>
<script src="https://HauyuChen.github.io/js/ui.js"></script>






</body>
</html>

