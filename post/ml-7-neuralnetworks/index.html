<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="机器学习系列-第 7 篇">
  <meta name="generator" content="Hugo 0.24.1" />

  <title>【机器学习笔记】7. 神经网络（一）：概述 &middot; Hov&#39;s Blog</title>

  <script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "https://hm.baidu.com/hm.js?dd096f3aba9332e2640cda59d3786695";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>	
  
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.2/pure-min.css">

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.2/grids-responsive-old-ie-min.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.2/grids-responsive-min.css">
  <!--<![endif]-->

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://HauyuChen.github.io/css/side-menu-old-ie.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://HauyuChen.github.io/css/side-menu.css">
  <!--<![endif]-->

  <link rel="stylesheet" href="https://HauyuChen.github.io/css/blackburn.css">

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

  
  <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">

  
  

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/styles/androidstudio.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  

  <link rel="shortcut icon" href="https://HauyuChen.github.io/img/favicon.ico" type="image/x-icon" />

  
  


</head>


<body>

<div id="layout">

  
<a href="#menu" id="menuLink" class="menu-link">
  
  <span></span>
</a>
<div id="menu">

  <a class="pure-menu-heading brand" href="https://HauyuChen.github.io/">
  <img src="https://HauyuChen.github.io/img/Hov.jpg" width="125px">
</a>

  <div class="pure-menu">
    <ul class="pure-menu-list">
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://HauyuChen.github.io/"><i class='fa fa-home fa-fw'></i>主页</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://HauyuChen.github.io/post/"><i class='fa fa-list fa-fw'></i>所有文章</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://HauyuChen.github.io/tags/"><i class='fa fa-folder fa-fw'></i>文章分类</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://HauyuChen.github.io/topics/"><i class='fa fa-tags fa-fw'></i>关键词</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://HauyuChen.github.io/about-me/"><i class='fa fa-user fa-fw'></i>关于我</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://HauyuChen.github.io/about-site/"><i class='fa fa-home fa-fw'></i>关于本站</a>
      
        </li>
      
    </ul>
  </div>

  <div class="pure-menu social">

  <ul class="pure-menu-list">
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://github.com/HauyuChen" target="_blank"><i class="fa fa-github-square fa-fw"></i>GitHub</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    
	</ul>
	<ul class="pure-menu-list">
	
	<li class="pure-menu-item">
      <a class="pure-menu-link" href="http://blog.csdn.net/u014134180" target="_blank"><i class="fa fa-lastfm-square fa-fw"></i>友链：Wu_Being</a>
    </li>
  </ul>
  
</div>


  <div>


</div>

</div>


  <div id="main">


<div class="header">
  <h1>【机器学习笔记】7. 神经网络（一）：概述</h1>
  <h2>机器学习系列-第 7 篇</h2>
</div>
<div class="content">

  <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2017-08-16</time>
  </div>

  

  
  
  
  <div>
    <i class="fa fa-folder fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="https://HauyuChen.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>
    
  </div>
  
  

  
  
  
  <div>
	<i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-topic" href="https://HauyuChen.github.io/topics/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>&nbsp;&#47;
    
      <a class="post-taxonomy-topic" href="https://HauyuChen.github.io/topics/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">神经网络</a>&nbsp;&#47;
    
      <a class="post-taxonomy-topic" href="https://HauyuChen.github.io/topics/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">监督学习</a>
    
  </div>
  
  
  
</div>

  

<hr />

<p><em>作者注：机器学习系列是本人在学习机器学习相关内容时产生的笔记，希望也能对您有所帮助。值得注意的是，作者作为初学者，表述难免有误或不全面，望多批评指正。<br/>
如有任何问题，欢迎您随时与我联系：Hauyu.Chen@Gmail.com</em></p>

<p><em>版权声明：本文由 Hov 所有，发布于 <a href="http://chenhy.com">http://chenhy.com</a> ，转载请注明出处。<br/></em></p>

<hr />

<p><br/></p>

<h1 id="0-前言">0 前言</h1>

<p>前面我们已经掌握了机器学习的基本套路，通过模型、目标函数、优化算法实现一些简单的任务。</p>

<p>本文我们要开始学习神经网络，神经网络是非常重要的机器学习算法。我们将通过学习神经网络，了解如何将单独的单元按照一定的规则连接，从而实现更加复杂的任务。</p>

<p><br/></p>

<h1 id="1-简介">1 简介</h1>

<p>对人类而言，我们的视觉、听觉由大脑的神经中枢产生，而神经中枢由大量的神经元相互连接而成。一个神经元通过树突（Dendrite）接收其它神经元传来的化学物质（信息），从而改变该神经元的电位，当电位到达某一阈值（Threshold）时，该神经元被激活，即“兴奋”起来，从而通过轴突（Axon terminal）向其它神经元发送化学物质（信息）。</p>

<p>下图为一个神经元。</p>

<p><br/></p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-01.png" alt="" /></p>

<p><br/></p>

<p>顾名思义，神经网络是一种模拟大脑的算法。神经网络中最基本的成分是神经元模型（ Neural Model ，又称 Logistic Unit ）。神经元模型就是模拟上述神经元接收信息并传递信息的过程，一个神经元为一层。神经网络将多个单一的“神经元”联结在一起，一个“神经元”的输出可以作为另一个“神经元”的输入。</p>

<p><br/></p>

<h1 id="2-神经网络模型">2 神经网络模型</h1>

<p>在监督学习中，我们有一组训练数据 ( x( i ), y( i ) ) ，神经网络算法能提供一种复杂的非线性的假设模型 hθ(x) ，以参数 θ 来拟合我们的数据。</p>

<p>一个简单的神经网络如下所示：</p>

<p><br/></p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-02.PNG" alt="" /></p>

<p><br/></p>

<p>上面的神经网络只有一个“神经元”，最左的一层（蓝色圆圈）为输入层，最右的一层为输出层，中间为隐藏层。 x1、x2、x3 为输入单元， a1、a2、a3 为隐藏单元， hθ(x) 为输出单元。特别的， x0、a0 是我们单独增加的偏置单元。</p>

<p>在隐藏层中，<img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-03.PNG" alt="" /> 为激励单元。<img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-04.PNG" alt="" />为第 j 层的第 i 个激励单元。</p>

<p>在本文中，我们选用 sigmoid 函数作为激活函数，即神经元的输入 - 输出的映射关系为逻辑回归。</p>

<p><strong>举个栗子：</strong></p>

<p>如果隐藏层只有一层，如下：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-06.PNG" alt="" /></p>

<p>其中， x1、x2、x3 是训练数据中的输入， x0 是偏置单元。</p>

<p>第二层从上往下分别为第二层的第 1、2、3 个激励单元。激励单元可通过以下公式计算：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-07.PNG" alt="" /></p>

<p>g( ) 为逻辑函数，即单个神经元的输入和输出之间的映射关系为逻辑回归。</p>

<p>每一层有其对应的权值，<img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-10.PNG" alt="" />为第 j 层节点的权值。如果第 j 层有 s( j ) 个单元，第 j+1 层有 s( j+1 ) 个单元，则<img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-10.PNG" alt="" />为 <img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-11.PNG" alt="" /> 矩阵, +1 是因为还要加上偏置单元 x0 。</p>

<p>第三层为假设函数，即为最后的输出，我们也可认为它是<img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-08.PNG" alt="" />，同理，其计算公式如下：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-09.PNG" alt="" /></p>

<p><br/></p>

<h1 id="3-前向传播">3 前向传播</h1>

<p><br/></p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-12.PNG" alt="" /></p>

<p>我们用一个新的变量 z 来表示 g(···) 里面的内容，所以有：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-13.PNG" alt="" /></p>

<p>也就是说，对于第二层的第 k 个节点，变量 z 可表示如下：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-14.PNG" alt="" /></p>

<p>将 x 和 z 向量化：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-15.PNG" alt="" /></p>

<p>令<img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-16.PNG" alt="" />，则：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-17.PNG" alt="" /></p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-18.PNG" alt="" /></p>

<p>所以，</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-19.PNG" alt="" /></p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-20.PNG" alt="" /></p>

<p>我们将上面的计算步骤称为前向传播。通过<img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-16.PNG" alt="" /> 表示输入层的激活值，那么以此类推可求得第 j 层的激活值<img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-18.PNG" alt="" />，最终计算出第 j+1 层（输出层）的激活值<img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-39.PNG" alt="" />，也就是<img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-37.PNG" alt="" />。</p>

<p>前向传播通过矩阵向量的运算方式，可快速求解神经网络。</p>

<p><br/></p>

<h1 id="4-实例">4 实例</h1>

<p>下面我们通过实例说明神经网络的应用原理。</p>

<h2 id="4-1-and运算">4.1 AND运算</h2>

<p>AND 运算相信大家都熟悉，x1 AND x2 只有当 x1=1 且 x2=1 ，结果为 1 ，否则为 0 。</p>

<p>AND 运算可通过加法器来求，那么有没有其它的方法呢？当然有，神经网络也可以。</p>

<p>通过神经网络实现 AND 运算，神经网络模型如下：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-21.PNG" alt="" /></p>

<p>注：x0为偏置单元，x0=1。</p>

<p>设参数向量为：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-22.PNG" alt="" />，</p>

<p>所以假设模型为：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-23.PNG" alt="" /></p>

<p>g 为逻辑函数，其图像如下：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-24.PNG" alt="" /></p>

<p>所以，只有当 x1=1 且 x2=2 ，结果为 1 。</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-25.PNG" alt="" /></p>

<p>至此，我们通过神经网络实现了基本的 AND 运算。同理， OR 运算也可以通过这样的方式实现，只不过参数向量修改一下即可。</p>

<p>AND 、 NOR 、 OR 运算对应的参数向量如下：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-26.PNG" alt="" /></p>

<h2 id="4-2-xnor运算">4.2 XNOR运算</h2>

<p>单一的 AND 、 OR 运算过于简单，下面我们通过神经网络来实现 XNOR 运算，以更好地领悟神经网络的精髓。</p>

<p>XNOR 运算：只有 x1 、 x2 都为 0 或都为 1 ，结果为 1 。</p>

<p>神经网络模型如下：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-27.PNG" alt="" /></p>

<p>以 AND 和 NOR 为第一层的参数向量，</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-31.PNG" alt="" /></p>

<p>所以，第一层的参数向量如下：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-28.PNG" alt="" /></p>

<p>以 OR 为第二层的参数向量，</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-32.PNG" alt="" /></p>

<p>所以，第二层的参数向量如下：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-29.PNG" alt="" /></p>

<p>综上，神经网络图解如下：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-33.PNG" alt="" /></p>

<p>第一层输入为 +1 ( 即x0 )、 x1 、 x2 ，输出为 <img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-34.PNG" alt="" /> 、<img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-35.PNG" alt="" /> 。</p>

<p>第一层的输出为第二层的输入，所以第二层的输入为 +1 （即<img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-34.PNG" alt="" />） 、<img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-34.PNG" alt="" />、<img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-35.PNG" alt="" />，第二层的输出为<img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-08.PNG" alt="" />，也就是<img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-37.PNG" alt="" />。</p>

<p>由前向传播的计算思路，有：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-30.PNG" alt="" /></p>

<p>真值表如下：</p>

<p><img src="https://raw.githubusercontent.com/HauyuChen/PicsBox/master/NN-38.PNG" alt="" /></p>

<p>至此，我们成功通过神经网络实现 XNOR 运算。神经网络实质上是将较简单的运算组合成较复杂的运算，以此实现更强大的功能。比如，在栗子中我们将简单运算 AND 、 OR 、 NOR 结合，实现复杂的 XNOR 运算。</p>

<p><br/></p>


  
<div class="prev-next-post pure-g">
  <div class="pure-u-1-24" style="text-align: left;">
    
    <a href="https://HauyuChen.github.io/post/ml-6-regulation/"><i class="fa fa-chevron-left"></i></a>
    
  </div>
  <div class="pure-u-10-24">
    
    <nav class="prev">
      <a href="https://HauyuChen.github.io/post/ml-6-regulation/">【机器学习笔记】6. 正则化</a>
    </nav>
    
  </div>
  <div class="pure-u-2-24">
    &nbsp;
  </div>
  <div class="pure-u-10-24">
    
    <nav class="next">
      <a href="https://HauyuChen.github.io/post/dp_singleton_pattern/">【设计模式】1. 单例模式</a>
    </nav>
    
  </div>
  <div class="pure-u-1-24" style="text-align: right;">
    
    <a href="https://HauyuChen.github.io/post/dp_singleton_pattern/"><i class="fa fa-chevron-right"></i></a>
    
  </div>
</div>



  
<div id="disqus_thread"></div>
<script type="text/javascript">

(function() {
    
    
    if (window.location.hostname == "localhost")
        return;

    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    var disqus_shortname = "http-hov-space";
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


</div>

</div>
</div>
<script src="https://HauyuChen.github.io/js/ui.js"></script>






</body>
</html>

